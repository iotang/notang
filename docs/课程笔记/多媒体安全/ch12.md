# 第 12 章：隐写术

## 使用 LSB 技术

把图片的像素值表示成整数的形式。把 $2 i$ 变成 $2i + 1$ 表示编码了一个 1；把 $2i + 1$ 变成 $2i$ 表示编码了一个 0。这样会导致像素值分布变得很“平整”：$2i$ 和 $2i + 1$ 的数量会趋近。

## DCT 图像压缩

DCT 将图像分成由不同频率组成的小块，然后进行量化。在量化过程中，舍弃高频分量，剩下的低频分量被保存下来用于后面的图像重建。

- 将图像分解为 $8 \times 8$ 的图像块
- 将表示像素的 RGB 系统转换成 YUV （灰阶与色度）系统
- 然后从左至右，从上至下对每个图像块做 DCT 变换，也就是把每一个块表达为 64 个图案乘上不同系数的和；然后舍弃高频分量，保留 19 个低频分量
- 对余下的图像块进行量化压缩
- 解压缩时对每个图像块做DCT反转换（IDCT）

DCT 变换得到的 64 个系数中，第一个是 DC 系数，后 63 个是 AC 系数。“舍弃高频分量”这一步叫做 DCT 量化，是一种不可逆的有损压缩过程。使用一张量化表除以 DCT 系数的矩阵，量化后的比例系数中数值较大的被映射到非零的整数，数值较小的系数被映射到零。映射完的系数叫做 JPEG 系数。请看这里：[链接](https://blog.csdn.net/freee12/article/details/109953732)。

量化系数 $X$ 的频率有这样的规律：$P(X = 1) > P(X = 2) > P(X = 3) > \cdots$，并且 $P(X = 1) - P(X = 2) > P(X = 2) - P(X = 3) > P(X = 3) - P(X = 4) > \cdots$。

### 统计数据保存隐写术

现在拿一对 $(U, L)$ 出来做 LSB，其中 $U$ 比 $L$ 多。让它们各自拿出比例为 $q \in [0, 1]$ 的量来隐写，结果是：

$U$ 方：有 $U \cdot (1 - q)$ 不变，获得来自双方的 $(U + L) \cdot \frac{q}{2}$，最后变为 $U - (U - L) \cdot \frac{q}{2}$。

$L$ 方：有 $L \cdot (1 - q)$ 不变，获得来自双方的 $(U + L) \cdot \frac{q}{2}$，最后变为 $L + (U - L) \cdot \frac{q}{2}$。

为了不让双方大小比例变得太奇怪，我们必须满足 $(U - L) \cdot \frac{q}{2} < L \cdot (1 - q)$，也就是 $q < \frac{2L}{U + L}$。

### 基于模型的隐写术

*说实话我不知道自己在写啥。*

把载体看作是一个 8 位随机数，其中高 7 位和隐写无关，只有最低一位和隐写有关（可以修改）。设高 7 位是 $c_{inv}$，最低一位是 $c_{emb}$。基于模型的隐写术可以看作是一种条件概率的集合：$P(c_{emb} | c_{inv})$。用一个熵解码器将载体调整成满足 $P(c_{emb} | c_{inv})$ 的样子，把载体的（看作是）均匀分布的字节流**解码**成广义柯西分布的字节流，概率密度函数 $P(x) = \frac{p - 1}{2s} |\frac{|x|}{s} + 1|^{-p}$。

在 $(2i, 2i + 1)$ 的 $2i$ 的概率 $p_0 = P(c_{emb} = 0 | c_{inv} = MSB_7 (2i)) = \frac{T_c [2i]}{T_c [2i] + T_c [2i + 1]} = 1 - P(c_{emb} = 1 | c_{inv} = MSB_7 (2i))$

在解读隐写信息的时候，就将广义柯西分布的字节流**编码**成均匀分布的字节流。

这种方法的效率是 2：每一位只有一半的几率改变，而可以表示一整位的编码信息。

信息熵 $H(p_0) = - p_0 \log_2 p_0 - (1 - p_0) \log_2 (1 - p_0)$

位的改变 $= p_0 (1 - p_0) + (1 - p_0) p_0 = 2 p_0 (1 - p_0)$

效率 $= \frac{H(p_0)}{2 p_0 (1 - p_0)}$

### JSTEG

JSTEG 把信息用 LSB 编码到 JPEG 系数里面，它的问题是量化系数分布会有明显的特征。

### F3

- 如果对应编码信息为 0，那么把 JPEG 值移到更靠近 0 的偶数（-3 到 -2， -2 到 -2，3 到 2）。
- 如果对应编码信息为 1，那么把 JPEG 值移到更靠近 0 的奇数（-3 到 -3， -2 到 -1，2 到 1）。
- 如果有人被移到了 0，那么不会消耗这一位要编码的信息。

其问题是，一般来说 $P(2i - 1) > P(2i)$；但是如果数据足够险恶，可能会让编码后信息中 $P(2i - 1) < P(2i)$。

### F4

JPEG 值大于 0：

- 如果对应编码信息为 0，那么把 JPEG 值移到更靠近 0 的偶数。
- 如果对应编码信息为 1，那么把 JPEG 值移到更靠近 0 的奇数。
- 如果有人被移到了 0，那么不会消耗这一位要编码的信息。

JPEG 值小于 0 的时候，反过来：

- 如果对应编码信息为 0，那么把 JPEG 值移到更靠近 0 的奇数。
- 如果对应编码信息为 1，那么把 JPEG 值移到更靠近 0 的偶数。
- 如果有人被移到了 0，那么不会消耗这一位要编码的信息。

## 矩阵编码

现在想往三个灰度值 $x_1$、$x_2$ 和 $x_3$ 中编码两位信息 $b_1$ 和 $b_2$。隐写追求最少量的更改，我们可以最多更改 $x_1$、$x_2$ 和 $x_3$ 中的一个来编码 $b_1$ 和 $b_2$：

$b_1 = LSB(x_1)\ \mathrm{xor}\ LSB(x_2)$，$b_2 = LSB(x_2)\ \mathrm{xor}\ LSB(x_3)$。

如果 $b_1$ 不满足，那就修改 $x_1$；如果 $b_2$ 不满足，那就修改 $x_3$；如果都不满足，那就修改 $x_2$。这样子的话预期修改位的数量是 $\frac{3}{4}$，效率是 $2 / \frac{3}{4} = \frac{8}{3}$。

### 海明码

- 把 $2^p$ 个信息编码到一个大小为 $2^{2^p - 1}$ 的空间中。
- 对于一个 $2^{2^p - 1}$ 位的数 $c$，构造矩阵 $H \in \{0, 1\}^{p \times (2^p - 1)}$ 提取出 $p$ 位信息：$m = Hc$。这样就把信息 $m$ 映射为了 $c$。

对于一个 $p$ 位信息，如果只纠错 1 位，

- 有 $1 / 2^p$ 的概率 $m = Hc$，也就是没有错。
- 有 $1 - 1 / 2^p$ 的概率 $m = H(c + e_i)$，其中向量 $e_i$ 里面只有一个 1，其他位置都是 0。

这样一来，改变的位数期望是 $1 - 1 / 2^p$，效率是 $p / (1 - 1 / 2^p)$。

## 编码效率的上限

在一张 n 个像素的载体中，编码集合为 $M$ 的信息，所需要改变的最少位数 $R$ 是多少？

在这里，效率即是 $\frac{\log_2 |M|}{R}$，当它达到它的上界时说明来到了最佳状态。

当 $R$ 固定的时候，给 $n$ 个像素改变最多 $R$ 位的方法数为 $\sum_{i = 0}^{R} \binom{n}{i} 2^i$，于是我们有这个上限：$\log_2 |M| \leq \log_2 (\sum_{i = 0}^{R} \binom{n}{i} 2^i)$。

根据信息论的知识（我不知道），$\log_2 |M| \leq \log_2 (\sum_{i = 0}^{R} \binom{n}{i} 2^i) \leq n H(R/n)$，其中二元熵函数 $H(x) = -x \log_2 x - (1 - x) \log_2 (1 - x)$。

于是我们有相对消息长度 $\alpha_{max} = \frac{\log_2 |M|}{n} \leq H(R / n)$。效率 $e = \frac{\log_2 |M|}{R} \leq \frac{\alpha}{H^{-1} (\alpha)}$。

## 湿纸

只能更改一部分地方的载体叫做湿纸（Wet Paper），能被修改的地方叫做“干”的地方。现在有湿纸 $x$ 和信息 $m$，我们需要在只更改干的地方的情况下把信息改成 $y$ 以编码信息：$D_{m \times n} y_{n \times 1} = m_{m \times 1}$，$D$ 是加解密双方共享的矩阵。

设 $y = x + v$，也就是我们要让 $D(x + v) = m$，$Dv = m - Dx$。

规定矩阵 $P$ 有这样的效果：$Pv = (u_1, u_2, \cdots, u_{|J|}, 0, 0, \cdots, 0)^T = (u, 0)^T$，即把湿的地方都放到后面。

$Dv = m - Dx = z$；$(DP^{-1}) (Pv) = z$，$(H\ K) (u\ 0)^{T}$，$H_{m \times |J|} u = z$。我们就解这个 $u$。
